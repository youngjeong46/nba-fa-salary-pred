{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "I am acting as an NBA consultant; based on the 3-year performances of players before becoming Free Agents and the contract they ended up signing (calculated per year), I want to predict how this year's free agents will do (the 2018-19 season is only 1-2 games from being over). Teams targeting certain free agents in the Summer of '19 will be able to use this to determine who they want to target as their main pursuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "*Describe your data sources here and explain why they are relevant to the problem you are trying to solve.*\n",
    "\n",
    "First I will scrape data from basketball-reference.com that has player's individual statitstics per season from 2008-2009 to 2017-18 seasons. This will contain data with various player statistics that I can either use as my features or \n",
    "\n",
    "I will also scrape free agent lists from 2011 to 2018 seasons that will help me filter out non-impending free agents. This along with the salary they signed up for is available on spotrac.com. This data will help me collect \"y\".\n",
    "\n",
    "*After completing this step, be sure to edit `references/data_dictionary` to include descriptions of where you obtained your data and what information it contains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/data/make_dataset.py\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# helper functions go here\n",
    "def download_pergame_data(year_from,year_to):\n",
    "    data =[]\n",
    "    years = range(year_from, year_to+1)\n",
    "    for i in years:\n",
    "        url = 'https://www.basketball-reference.com/leagues/NBA_'+i+'_per_game.html'\n",
    "        if requests.get(url).status_code == 200:\n",
    "            page=requests.get(url).text\n",
    "            data_soup = BeautifulSoup(page,\"html.parser\")\n",
    "            player_data=data_soup.find(class_='sortable stats_table');\n",
    "            players = [row for row in player_data.find_all('tr')]\n",
    "            \n",
    "            headers = players[0].find_all('th')\n",
    "            columns = [i.text for i in headers[1:]]\n",
    "            \n",
    "            df = pd.DataFrame(columns=columns)\n",
    "            \n",
    "            for entry in players[1:]:\n",
    "                temp = entry.find_all('td')\n",
    "                temp = [stat.text for stat in temp]\n",
    "                if len(temp) == len(columns):\n",
    "                    df.loc[len(df)] = temp\n",
    "            master_data.append(df)\n",
    "    return data, years\n",
    "            \n",
    "def save_pergame_data():\n",
    "            \n",
    "            \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that download data from one or more sources\n",
    "    and saves those datasets to the data/raw directory.\n",
    "    \"\"\"\n",
    "    # download_dataset_1(url)\n",
    "    # download_dataset_2(url)\n",
    "    # save_dataset_1('data/raw', filename)\n",
    "    # save_dataset_2('data/raw', filename)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "*Look through the raw data files and see what you will need to do to them in order to have a workable data set. If your source data is already well-formatted, you may want to ask yourself why it hasn't already been analyzed and what other people may have overlooked when they were working on it. Are there other data sources that might give you more insights on some of the data you have here?*\n",
    "\n",
    "*The end goal of this step is to produce a [design matrix](https://en.wikipedia.org/wiki/Design_matrix), containing one column for every variable that you are modeling, including a column for the outputs, and one row for every observation in your data set. It needs to be in a format that won't cause any problems as you visualize and model your data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/features/build_features.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/raw, cleans them,\n",
    "    and converts the data into a design matrix that is ready for modeling.\n",
    "    \"\"\"\n",
    "    # clean_dataset_1('data/raw', filename)\n",
    "    # clean_dataset_2('data/raw', filename)\n",
    "    # save_cleaned_data_1('data/interim', filename)\n",
    "    # save_cleaned_data_2('data/interim', filename)\n",
    "    # build_features()\n",
    "    # save_features('data/processed')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed')\n",
    "    # describe_features(data, 'reports/')\n",
    "    # generate_charts(data, 'reports/figures/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you learn? What relationships do you think will be most helpful as you build your model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "*Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed/')\n",
    "    # train, test = train_test_split(data)\n",
    "    # save_train_test(train, test, 'data/processed/')\n",
    "    # model = build_model()\n",
    "    # model.fit(train)\n",
    "    # save_model(model, 'models/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # test_X, test_y = load_test_data('data/processed')\n",
    "    # trained_model = load_model('models/')\n",
    "    # predictions = trained_model.predict(test_X)\n",
    "    # metrics = evaluate(test_y, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
